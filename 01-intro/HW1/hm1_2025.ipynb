{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09b1718",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module.\n",
    "\n",
    "\n",
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"**Green** Taxi Trip Records\", we'll use \"**Yellow** Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "* 16\n",
    "* 17\n",
    "* 18\n",
    "* 19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5a0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2973a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e6d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5254d93b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f909991",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "* 32.59\n",
    "* 42.59\n",
    "* 52.59\n",
    "* 62.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d85fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "df['duration'] = (df['dropoff_datetime'] - df['pickup_datetime']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51472a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of duration: 42.59 minutes\n"
     ]
    }
   ],
   "source": [
    "std_duration = df['duration'].std()\n",
    "print(f'Standard deviation of duration: {std_duration:.2f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bfd981",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "* 90%\n",
    "* 92%\n",
    "* 95%\n",
    "* 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0037c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df['duration'] >= 1) & (df['duration'] <= 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6406c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.1220282212598"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered)/len(df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8903d",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will \n",
    "  label encode them)\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "* 2\n",
    "* 155\n",
    "* 345\n",
    "* 515\n",
    "* 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffceb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "df = df_filtered\n",
    "df[categorical] = df[categorical].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8740f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts = df[categorical].to_dict(orient='records')\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b2500fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix size: (3009173, 515)\n"
     ]
    }
   ],
   "source": [
    "print(f'Feature matrix size: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9285e3",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters, where duration is the response variable\n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 3.64\n",
    "* 7.64\n",
    "* 11.64\n",
    "* 16.64m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa249763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.649261027919939"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'duration'\n",
    "y_train = df[target].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "mean_squared_error(y_train, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852b676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0cb3fb",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2023). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 3.81\n",
    "* 7.81\n",
    "* 11.81\n",
    "* 16.81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b463133",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfff8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = read_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24e069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val RMSE: 7.778947591741755\n"
     ]
    }
   ],
   "source": [
    "val_dicts = df_val[categorical].to_dict(orient='records')\n",
    "dv = DictVectorizer()\n",
    "X_val = dv.fit_transform(val_dicts) \n",
    "y_val = df_val.duration.values\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_val, y_val)\n",
    "y_pred = lr.predict(X_val)\n",
    "print(f'Val RMSE: {mean_squared_error(y_val, y_pred, squared=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da6895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
