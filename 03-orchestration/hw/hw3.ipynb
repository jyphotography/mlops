{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d1f8e6",
   "metadata": {},
   "source": [
    "First, let's run Mage with Docker Compose. Follow the quick start guideline.\n",
    "\n",
    "What's the version of Mage we run?\n",
    "\n",
    "(You can see it in the UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./scripts/start.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v0.9.73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19627323",
   "metadata": {},
   "source": [
    "Now let's create a new project. We can call it \"homework_03\", for example.\n",
    "\n",
    "How many lines are in the created metadata.yaml file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22764bd9",
   "metadata": {},
   "source": [
    "1. text editor\n",
    "2. new Mage Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe5064",
   "metadata": {},
   "source": [
    "55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c5b6a5",
   "metadata": {},
   "source": [
    "Let's create an ingestion code block.\n",
    "\n",
    "In this block, we will read the March 2023 Yellow taxi trips data.\n",
    "\n",
    "How many records did we load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f5d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_files(**kwargs) -> pd.DataFrame:\n",
    "\n",
    "    response = requests.get(\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet'\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.text)\n",
    "\n",
    "    df = pd.read_parquet(BytesIO(response.content))\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa3910",
   "metadata": {},
   "source": [
    "3403766 rows x 19 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a05c1",
   "metadata": {},
   "source": [
    "Let's use the same logic for preparing the data we used previously. We will need to create a transformer code block and put this code there.\n",
    "\n",
    "This is what we used (adjusted for yellow dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5aecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "@transformer\n",
    "def transform(data, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Template code for a transformer block.\n",
    "\n",
    "    Add more parameters to this function if this block has multiple parent blocks.\n",
    "    There should be one parameter for each output variable from each parent block.\n",
    "\n",
    "    Args:\n",
    "        data: The output from the upstream parent block\n",
    "        args: The output from any additional upstream blocks (if applicable)\n",
    "\n",
    "    Returns:\n",
    "        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n",
    "    \"\"\"\n",
    "    # Specify your transformation logic here\n",
    "    data.tpep_dropoff_datetime = pd.to_datetime(data.tpep_dropoff_datetime)\n",
    "    data.tpep_pickup_datetime = pd.to_datetime(data.tpep_pickup_datetime)\n",
    "\n",
    "    data['duration'] = data.tpep_dropoff_datetime - data.tpep_pickup_datetime\n",
    "    data.duration = data.duration.dt.total_seconds() / 60\n",
    "\n",
    "    data = data[(data.duration >= 1) & (data.duration <= 60)]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440243c5",
   "metadata": {},
   "source": [
    "3316216 rows x 20 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28fbb87",
   "metadata": {},
   "source": [
    "We will now train a linear regression model using the same code as in homework 1.\n",
    "\n",
    "* Fit a dict vectorizer.\n",
    "* Train a linear regression with default parameters.\n",
    "* Use pick up and drop off locations separately, don't create a combination feature.\n",
    "\n",
    "Let's now use it in the pipeline. We will need to create another transformation block, and return both the dict vectorizer and the model.\n",
    "\n",
    "What's the intercept of the model? \n",
    "\n",
    "Hint: print the `intercept_` field in the code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebbd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "@transformer\n",
    "def transform(df, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Template code for a transformer block.\n",
    "\n",
    "    Add more parameters to this function if this block has multiple parent blocks.\n",
    "    There should be one parameter for each output variable from each parent block.\n",
    "\n",
    "    Args:\n",
    "        data: The output from the upstream parent block\n",
    "        args: The output from any additional upstream blocks (if applicable)\n",
    "\n",
    "    Returns:\n",
    "        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n",
    "    \"\"\"\n",
    "    # Specify your transformation logic here\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    train_dicts = df[categorical].to_dict(orient='records')\n",
    "    dv = DictVectorizer()\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    target = 'duration'\n",
    "    y_train = df[target].values\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(lr.intercept_)\n",
    "\n",
    "    return dv, lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006a3568",
   "metadata": {},
   "source": [
    "The model is trained, so let's save it with MLFlow.\n",
    "\n",
    "If you run mage with docker-compose, stop it with Ctrl+C or \n",
    "\n",
    "```bash\n",
    "docker-compose down\n",
    "```\n",
    "\n",
    "Let's create a dockerfile for mlflow, e.g. `mlflow.dockerfile`:\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.10-slim\n",
    "\n",
    "RUN pip install mlflow==2.12.1\n",
    "\n",
    "EXPOSE 5000\n",
    "\n",
    "CMD [ \\\n",
    "    \"mlflow\", \"server\", \\\n",
    "    \"--backend-store-uri\", \"sqlite:///home/mlflow_data/mlflow.db\", \\\n",
    "    \"--host\", \"0.0.0.0\", \\\n",
    "    \"--port\", \"5000\" \\\n",
    "]\n",
    "```\n",
    "\n",
    "And add it to the docker-compose.yaml:\n",
    "\n",
    "```yaml\n",
    "  mlflow:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: mlflow.dockerfile\n",
    "    ports:\n",
    "      - \"5000:5000\"\n",
    "    volumes:\n",
    "      - \"${PWD}/mlflow_data:/home/mlflow_data/\"\n",
    "    networks:\n",
    "      - app-network\n",
    "```\n",
    "\n",
    "Note that `app-network` is the same network as for mage and postgres containers.\n",
    "If you use a different compose file, adjust it.\n",
    "\n",
    "We should already have `mlflow==2.12.1` in requirements.txt in the mage project we created for the module. If you're starting from scratch, add it to your requirements.\n",
    "\n",
    "Next, start the compose again and create a data exporter block.\n",
    "\n",
    "In the block, we\n",
    "\n",
    "* Log the model (linear regression)\n",
    "* Save and log the artifact (dict vectorizer)\n",
    "\n",
    "If you used the suggested docker-compose snippet, mlflow should be accessible at `http://mlflow:5000`.\n",
    "\n",
    "Find the logged model, and find MLModel file. What's the size of the model? (`model_size_bytes` field):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
