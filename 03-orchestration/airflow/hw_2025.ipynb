{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a7d68e",
   "metadata": {},
   "source": [
    "\n",
    "The goal of this homework is to create a simple training pipeline, use mlflow to track experiments and register best model, but use Mage for it.\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page), the **Yellow** taxi data for March, 2023. \n",
    "\n",
    "## Question 1. Select the Tool\n",
    "\n",
    "You can use the same tool you used when completing the module,\n",
    "or choose a different one for your homework.\n",
    "\n",
    "What's the name of the orchestrator you chose? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ce47b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e2f10d",
   "metadata": {},
   "source": [
    "## Question 2. Version\n",
    "\n",
    "What's the version of the orchestrator? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f40ab",
   "metadata": {},
   "source": [
    "  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:3.0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177f941",
   "metadata": {},
   "source": [
    "## Question 3. Creating a pipeline\n",
    "\n",
    "Let's read the March 2023 Yellow taxi trips data.\n",
    "\n",
    "How many records did we load? \n",
    "\n",
    "- 3,003,766\n",
    "- 3,203,766\n",
    "- 3,403,766\n",
    "- 3,603,766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "def ingest_files(**context):\n",
    "    url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.text)\n",
    "    df = pd.read_parquet(BytesIO(response.content))\n",
    "    df.to_parquet('/tmp/yellow_taxi_2023_03.parquet')\n",
    "    print(f\"Saved to /tmp/yellow_taxi_2023_03.parquet, total records: {len(df)}\")\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'start_date': datetime(2024, 1, 1),\n",
    "    'retries': 1,\n",
    "}\n",
    "\n",
    "with DAG(\n",
    "    dag_id='download_yellow_taxi_data',\n",
    "    default_args=default_args,\n",
    "    schedule=None,  # Use 'schedule' instead of 'schedule_interval'\n",
    "    catchup=False,\n",
    "    tags=['example'],\n",
    ") as dag:\n",
    "\n",
    "    download_task = PythonOperator(\n",
    "        task_id='download_and_save_yellow_taxi',\n",
    "        python_callable=ingest_files,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[2025-05-27, 15:05:33] INFO - Saved to /tmp/yellow_taxi_2023_03.parquet, total records: 3403766: chan=\"stdout\": source=\"task\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861bc8d3",
   "metadata": {},
   "source": [
    "## Question 4. Data preparation\n",
    "\n",
    "Let's continue with pipeline creation.\n",
    "\n",
    "We will use the same logic for preparing the data we used previously. \n",
    "\n",
    "This is what we used (adjusted for yellow dataset):\n",
    "\n",
    "```python\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df\n",
    "```\n",
    "\n",
    "Let's apply to the data we loaded in question 3. \n",
    "\n",
    "What's the size of the result? \n",
    "\n",
    "- 2,903,766\n",
    "- 3,103,766\n",
    "- 3,316,216 \n",
    "- 3,503,766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c881bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_print_size(**context):\n",
    "    df = read_dataframe('/tmp/yellow_taxi_2023_03.parquet')\n",
    "    print(f\"Filtered DataFrame size: {len(df)}\")\n",
    "\n",
    "with DAG(\n",
    "    dag_id='download_yellow_taxi_data',\n",
    "    default_args=default_args,\n",
    "    schedule=None,  # Use 'schedule' instead of 'schedule_interval'\n",
    "    catchup=False,\n",
    "    tags=['example'],\n",
    ") as dag:\n",
    "\n",
    "    download_task = PythonOperator(\n",
    "        task_id='download_and_save_yellow_taxi',\n",
    "        python_callable=ingest_files,\n",
    "    )\n",
    "\n",
    "    process_task = PythonOperator(\n",
    "        task_id='process_and_print_size',\n",
    "        python_callable=process_and_print_size,\n",
    "    )\n",
    "\n",
    "    download_task >> process_task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9780a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[2025-05-27, 15:13:18] INFO - Filtered DataFrame size: 3316216: chan=\"stdout\": source=\"task\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff8def",
   "metadata": {},
   "source": [
    "## Question 5. Train a model\n",
    "\n",
    "We will now train a linear regression model using the same code as in homework 1.\n",
    "\n",
    "* Fit a dict vectorizer.\n",
    "* Train a linear regression with default parameters.\n",
    "* Use pick up and drop off locations separately, don't create a combination feature.\n",
    "\n",
    "Let's now use it in the pipeline. We will need to create another transformation block, and return both the dict vectorizer and the model.\n",
    "\n",
    "What's the intercept of the model? \n",
    "\n",
    "Hint: print the `intercept_` field in the code block\n",
    "\n",
    "- 21.77\n",
    "- 24.77\n",
    "- 27.77\n",
    "- 31.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2559e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(**context):\n",
    "    df = read_dataframe('/tmp/yellow_taxi_2023_03.parquet')\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    # Ensure columns are string type before converting to dicts\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    train_dicts = df[categorical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "    target = 'duration'\n",
    "    y_train = df[target].values\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Model intercept: {lr.intercept_}\")\n",
    "\n",
    "    # In Airflow 3.x0, return values are automatically XCom pushed\n",
    "    # return dv, lr\n",
    "\n",
    "train_model_task = PythonOperator(\n",
    "    task_id='train_linear_regression_model',\n",
    "    python_callable=train_model,\n",
    ")\n",
    "\n",
    "download_task >> process_task >> train_model_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739be75a",
   "metadata": {},
   "source": [
    "[2025-05-27, 16:15:28] INFO - Model intercept: 24.778964270944773: chan=\"stdout\": source=\"task\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d861663",
   "metadata": {},
   "source": [
    "## Question 6. Register the model \n",
    "\n",
    "The model is trained, so let's save it with MLFlow.\n",
    "\n",
    "Find the logged model, and find MLModel file. What's the size of the model? (`model_size_bytes` field):\n",
    "\n",
    "* 14,534\n",
    "* 9,534\n",
    "* 4,534\n",
    "* 1,534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e93b7a",
   "metadata": {
    "vscode": {
     "languageId": "dockerfile"
    }
   },
   "outputs": [],
   "source": [
    "FROM python:3.10-slim\n",
    "\n",
    "RUN pip install mlflow==2.12.1\n",
    "\n",
    "EXPOSE 5000\n",
    "\n",
    "CMD [ \\\n",
    "    \"mlflow\", \"server\", \\\n",
    "    \"--backend-store-uri\", \"sqlite:///home/mlflow_data/mlflow.db\", \\\n",
    "    \"--host\", \"0.0.0.0\", \\\n",
    "    \"--port\", \"5000\" \\\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b103f",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "  mlflow:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: mlflow.dockerfile\n",
    "    ports:\n",
    "      - \"5001:5000\"\n",
    "    volumes:\n",
    "      - \"${PWD}/mlflow_data:/home/mlflow_data/\"\n",
    "    networks:\n",
    "      - app-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_latest_model(**context):\n",
    "    # Get the run_id from the previous task's XCom\n",
    "    ti = context['ti']\n",
    "    run_id = ti.xcom_pull(task_ids='train_linear_regression_model')\n",
    "\n",
    "    # Ensure the tracking URI is set for this task\n",
    "    mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "\n",
    "    if not run_id:\n",
    "        raise ValueError(\"Could not retrieve MLflow run_id from previous task.\")\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # The model was logged with artifact_path='model' in train_model task\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "    # Register the model. If the model name doesn't exist, it will be created.\n",
    "    model_name = \"nyc-taxi-lr-model\"\n",
    "    try:\n",
    "        model_details = mlflow.register_model(model_uri, name=model_name)\n",
    "        print(f\"Successfully registered model '{model_name}' version {model_details.version}\")\n",
    "\n",
    "        # Get model size\n",
    "        run_id_from_details = model_details.run_id\n",
    "        artifact_path = \"model\" # This is the artifact_path used in mlflow.sklearn.log_model\n",
    "        total_size_bytes = 0\n",
    "        try:\n",
    "            artifacts = client.list_artifacts(run_id_from_details, artifact_path)\n",
    "            for artifact in artifacts:\n",
    "                if artifact.is_dir:\n",
    "                    # If it's a directory, list its contents and sum their sizes\n",
    "                    sub_artifacts = client.list_artifacts(run_id_from_details, f\"{artifact_path}/{artifact.path}\")\n",
    "                    for sub_artifact in sub_artifacts:\n",
    "                         if sub_artifact.file_size is not None:\n",
    "                            total_size_bytes += sub_artifact.file_size\n",
    "                elif artifact.file_size is not None:\n",
    "                    total_size_bytes += artifact.file_size\n",
    "\n",
    "            print(f\"Registered model size: {total_size_bytes} bytes\")\n",
    "\n",
    "        except Exception as size_e:\n",
    "            print(f\"Could not retrieve model size: {size_e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error registering model: {e}\")\n",
    "\n",
    "with DAG(\n",
    "    dag_id='download_yellow_taxi_data',\n",
    "    default_args=default_args,\n",
    "    schedule=None,  # Use 'schedule' instead of 'schedule_interval'\n",
    "    catchup=False,\n",
    "    tags=['example'],\n",
    ") as dag:\n",
    "\n",
    "    download_task = PythonOperator(\n",
    "        task_id='download_and_save_yellow_taxi',\n",
    "        python_callable=ingest_files,\n",
    "    )\n",
    "\n",
    "    process_task = PythonOperator(\n",
    "        task_id='process_and_print_size',\n",
    "        python_callable=process_and_print_size,\n",
    "    )\n",
    "\n",
    "    train_model_task = PythonOperator(\n",
    "        task_id='train_linear_regression_model',\n",
    "        python_callable=train_model,\n",
    "    )\n",
    "\n",
    "    register_model_task = PythonOperator(\n",
    "        task_id='register_latest_model',\n",
    "        python_callable=register_latest_model,\n",
    "    )\n",
    "\n",
    "    download_task >> process_task >> train_model_task >> register_model_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3953acf",
   "metadata": {},
   "source": [
    "[2025-05-28, 11:53:23] INFO - Successfully registered model 'nyc-taxi-lr-model' version 1: chan=\"stdout\": source=\"task\"\n",
    "[2025-05-28, 11:53:23] INFO - Registered model size: 18692 bytes: chan=\"stdout\": source=\"task\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
